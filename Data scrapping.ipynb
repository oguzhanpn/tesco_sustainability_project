{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e8ae802",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "import csv\n",
    "import html\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cf64cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Precompile regex\n",
    "price_regex = re.compile(\".*beans-price__text$\")\n",
    "\n",
    "# Configure webdriver\n",
    "options = Options()\n",
    "#options.headless = True # I tried to hide the GUI but Tesco detects and blocks this\n",
    "options.add_argument(\"--window-size=1920,1080\")  # set window size to native GUI size\n",
    "options.add_argument(\"start-maximized\")  # ensure window is full-screen\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffa20821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save image from URL\n",
    "def save_image(urls, file_path):\n",
    "    try:\n",
    "        for url in urls: \n",
    "            decoded_url = html.escape(url)\n",
    "\n",
    "            # print(file_path, 'trying url:', decoded_url)\n",
    "            try:\n",
    "                response = requests.get(decoded_url)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"{file_path} Failed to save image for an url: \\n   {url} \\nwhere all urls are: \\n   {urls}. \\n Error: {e}\")\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                image = Image.open(BytesIO(response.content))\n",
    "                image.save(file_path, format=\"PNG\")\n",
    "                # print(file_path, 'successfully saved image' )\n",
    "                return response, image\n",
    "            else:\n",
    "                pass\n",
    "                # print(file_path, 'response: ', response.status_code, response.text)\n",
    "\n",
    "            \n",
    "        print(file_path, f\"Failed to save image all urls are tried: {urls}! \")\n",
    "        return None, None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(file_path, f\"Failed to save image from {urls}. Error: {e}\")\n",
    "        return None, None\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35921232",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_line_to_csv_file(file_path, data):\n",
    "\n",
    "    # Open the CSV file in append mode\n",
    "    with open(file_path, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529e290a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting marketplace category\n"
     ]
    }
   ],
   "source": [
    "data_file_path = 'product_data.csv'\n",
    "\n",
    "category_list = ['marketplace', 'summer', 'fresh-food', 'bakery', \n",
    "                 'frozen-food', 'treats-and-snacks', 'food-cupboard', 'drinks']\n",
    "\n",
    "# Load page\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "for _category in category_list:\n",
    "    print(f'Starting {_category}', 'category')\n",
    "    should_continue = True\n",
    "    _page = 1\n",
    "    while should_continue:\n",
    "        _page_start_time = time.time()\n",
    "        driver.get(f\"https://www.tesco.com/groceries/en-GB/shop/{_category}/all?page={_page}\")\n",
    "        _page += 1\n",
    "        time.sleep(5) # Let the page load\n",
    "\n",
    "        # Parse page\n",
    "        html_driver = driver.page_source\n",
    "        soup = BeautifulSoup(html_driver, 'html.parser')\n",
    "\n",
    "        # Get the product grid\n",
    "        grid = soup.find(\"ul\", attrs={\"data-auto\":\"product-list\"})\n",
    "        \n",
    "        if grid == None:\n",
    "            should_continue = False\n",
    "            break\n",
    "            \n",
    "        products = grid.find_all(\"li\")\n",
    "\n",
    "        # For each product...\n",
    "        for i, product in enumerate(products):\n",
    "            try:\n",
    "                # Zoom in\n",
    "                try:\n",
    "                    product = product.div.div.div.div # The relevant info is 4 divs deep\n",
    "                except:\n",
    "                    continue\n",
    "                \n",
    "                # Product id\n",
    "                product_id = product.find('a').get('href').split('/')[-1].strip()\n",
    "                \n",
    "                # Product name\n",
    "                name = product.find(\"a\", attrs={\"data-auto\":\"product-tile--title\"}).span.get_text().strip()\n",
    "\n",
    "                # Product price\n",
    "                try:\n",
    "                    price = product.find(\"p\", attrs={\"class\":price_regex}).get_text().strip()[1:] # remove the £\n",
    "                except:\n",
    "                    price = None\n",
    "                    \n",
    "                # Category info:\n",
    "                rest_of_shelf_links = product.select('a[href*=\"/groceries/en-GB/shop/\"]')\n",
    "\n",
    "                category_info = None\n",
    "                for href_link in rest_of_shelf_links:\n",
    "                    try:\n",
    "                        category_info = href_link.get('href')\n",
    "                        break\n",
    "                    except:\n",
    "                        pass\n",
    "                \n",
    "                # Print for debug\n",
    "                data_to_save = {\n",
    "                                'product_id': product_id, \n",
    "                                'name': name, \n",
    "                                'price': price, \n",
    "                                'category_info': category_info,\n",
    "                                'broad_category': _category, \n",
    "                                'page': _page\n",
    "                }\n",
    "                add_line_to_csv_file(data_file_path, list(data_to_save.values()))\n",
    "                \n",
    "                try:\n",
    "                    # Save image\n",
    "                    # Image URL\n",
    "                    image_urls = product.img.get('srcset').split(\", \")\n",
    "                    \n",
    "                    file_path = f\"product_images/{product_id}.png\"\n",
    "                    img_response, image = save_image(image_urls, file_path)\n",
    "                except Exception as e:\n",
    "                    print(f'Error while getting the image for product id {product_id}! ', e) \n",
    "\n",
    "            except Exception as e:\n",
    "                print(\"Scraping failed. Error:\", e)\n",
    "                assert False\n",
    "                \n",
    "        print(_category, 'category page', _page -1, 'completed for ', i, 'products!', \n",
    "              'time_cost for the page:', time.time() - _page_start_time, 'seconds')\n",
    "        \n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bc60a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
